# ğŸ§  DataHive â€” Framework dâ€™Analyse de DonnÃ©es StructurÃ©

**DataHive** est un framework modulaire et scalable conÃ§u pour les Data Analysts, Data Engineers ou Chefs de Projet SI souhaitant structurer un pipeline complet de traitement et dâ€™analyse de donnÃ©es. Il sâ€™appuie sur **Streamlit**, **Jupyter**, **PostgreSQL** et une architecture logicielle claire inspirÃ©e des bonnes pratiques du dÃ©veloppement logiciel..

---

## ğŸš€ Objectifs

- Fournir un cadre rÃ©plicable pour les projets data
- Faciliter la collaboration entre Data Analysts, Data Scientists et DÃ©veloppeurs
- Proposer des composants rÃ©utilisables pour la transformation digitale des donnÃ©es

---

## ğŸ§± Architecture du projet

```bash
â”œâ”€â”€ config/               # Fichiers de configuration (routes, logs, paramÃ¨tres)
â”œâ”€â”€ data/                 # DonnÃ©es organisÃ©es par niveau
â”‚   â”œâ”€â”€ raw/              # DonnÃ©es brutes
â”‚   â”œâ”€â”€ processed/        # DonnÃ©es nettoyÃ©es
â”‚   â”œâ”€â”€ logs/             # Logs d'exÃ©cution
â”œâ”€â”€ docker-compose.yml    # DÃ©ploiement multi-service
â”œâ”€â”€ Dockerfile            # Conteneurisation de lâ€™app
â”œâ”€â”€ interactive/          # Espace pour scripts exploratoires
â”œâ”€â”€ notebooks/            # Jupyter Notebooks pour exploration
â”œâ”€â”€ public/app.py         # Point d'entrÃ©e Streamlit
â”œâ”€â”€ reports/              # Rapports automatiques
â”œâ”€â”€ src/automate/         # Pipeline spÃ©cifique : analyse dâ€™automates
â”‚   â”œâ”€â”€ ingestion/        # Chargement des donnÃ©es
â”‚   â”œâ”€â”€ preparation/      # Nettoyage et prÃ©-traitement
â”‚   â”œâ”€â”€ analysis/         # Analyses descriptives/statistiques
â”‚   â”œâ”€â”€ modeling/         # ModÃ©lisation machine learning
â”‚   â””â”€â”€ utils/            # Fonctions utilitaires
â”œâ”€â”€ tests/                # Tests unitaires
â”œâ”€â”€ vendor/dataHive/      # Composants core rÃ©utilisables
â””â”€â”€ visualization/        # UI Streamlit
```

## ğŸš€ FonctionnalitÃ©s
    ğŸ”„ Ingestion & nettoyage automatisÃ© des donnÃ©es

    ğŸ“Š Visualisation gÃ©ographique et analytique avec Streamlit & Folium

    âš™ï¸ Architecture modulaire Python (ingestion, prÃ©paration, analyse, modÃ©lisation)

    ğŸ§ª Notebooks Jupyter pour les tests et lâ€™exploration

    ğŸ›¢ï¸ Base de donnÃ©es PostgreSQL intÃ©grÃ©e

    ğŸ“¥ Interface PGAdmin pour la gestion des donnÃ©es
---
## ğŸ³ **Services Docker**

Le projet embarque plusieurs services orchestrÃ©s via Docker :
Service	Description
app	Application Streamlit (localhost:8501) â€” interface principale dâ€™analyse.
jupyter	JupyterLab (localhost:8888) â€” prototypage et exploration libre.
db	PostgreSQL 15 Alpine â€” base de donnÃ©es relationnelle pour la data.
pgadmin	PGAdmin 4 (localhost:5050) â€” interface graphique pour PostgreSQL.
